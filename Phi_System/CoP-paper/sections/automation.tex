\section{Programming on Abstraction \& Its Automation}

As φ-SL lifts the verification onto abstraction, CoP over φ-BI is also feasible to lift the programming.
Specifically, if the pre- and post-conditions of all Hoare triplets are in MTF, state sequents during the programming are either
\begin{itemize}
\item $\Gamma \mbar S \vdash \{x\tycolon T \mbar P\}$ specifying intuitively the current construction is on an abstract state $x$ regarding to $T$ and with pure and abstract constrain $P$.
\item $\Gamma \mbar S \vdash A \Longrightarrow [C]\{x\tycolon T \mbar P\}$ specifying that the pending procedure $C$ to be applied results in an abstract state $x$ w.r.t $T$; and antecedents $A$ are HHFs generated (cf. \cref{HHF}) from:
\begin{itemize}
\item procedure specifications $\{x \tycolon T \mbar P\}\,C\,\{ y \tycolon U \mbar Q\} $ that relate concrete program $C$ to a relation $x \mapsto y$ in an abstraction domain.
\item transformations of abstraction $\{x \tycolon T \mbar P\} \longrightarrow\; ?R \ast \{ y \tycolon U \mbar Q\}$.
\item pure assertions $!P$ representing proof obligations.
\end{itemize}
\end{itemize}
Programming closed in such forms has an elegant interpretation in abstraction.
Applying $A \Longrightarrow \{x\tycolon T \mbar P\}\,C\,\{y\tycolon U \mbar Q\}$ on state sequent $\Gamma \mbar S \vdash \{x\tycolon T \mbar P\}$ pictures applying an abstract function $x \mapsto y$ on abstract state $x$ and resulting in $y$.
The programming is thus lifted on to the abstract domain given by abstraction relations $T,U$, where all proof obligations generated by a VCG-ToA solver are abstract w.r.t the abstract domain, and transformations between abstraction are as flexible as implications and mechanized by VCG-ToA solvers.

Nonetheless, not all specifications of procedures are closed in MTF, such as the \texttt{IF} given in \cref{sec:wp}. For them, specific mechanisms are required to convert the assertions into MTF. This is the problem of \emph{Normalization}. Elaborated in \cref{solve-Normalization}, we give an exemplary algorithm normalizing the post-condition of \texttt{IF}.

Besides the Normalization, we also discuss VCG-ToA in \cref{solve-VCG-ToA}.
At last in \cref{solve-CoA} we discuss the problem of CoA, namely \emph{Choice of specification theorems under different Abstraction relations}:
Note all inputs (except the initial pre-condition $P_0$) of CoP automaton are theorems or rules, whereas what programmers input and what a verifier parses are usually names of procedures.
As a procedure may have multiple specification theorems in different abstraction, the automation has to determine which abstraction of which specification theorems are preferable and sometimes annotations from users are necessary.

Certainly the automation can enumerate and try every possible abstraction for each statements, but for each attempt it generates a set of proof obligations and there is no a general approach to determine which obligations are provable.
Then it is more a matter of intuitions and tastes.
In our implementation, we believe that presenting several alternative sets of proof obligations to users is bad a choice, so the automation always guesses the best abstraction according to the abstraction of the current state sequent, and if the guess is wrong, users have chances to give the correct abstraction by annotations.

%Programming on a low-level language that is closing to machine can be tiresome. Verifying programs on it can be even worse.
%φ-BI relieves this by lifting the 

\subsection{Solvers for Normalization}\label{solve-Normalization}

Normalizations for different forms of assertions require specialized solvers.
As a demonstration, the sub-section presents a solver normalizing assertions in form \small$(\xif c \xthen X \xelse Y)$\normalsize\, for $X,Y$ in MTF, which is a problem of resolving or expanding a conditional abstraction to expose its abstract state and abstraction relation.
%, which is also the post-condition of \texttt{IF}.

The solver works in a logic programming consisting of several rules concerning the proposition $\XNIF(c,X,Y,?Z) \triangleq (\xif c \xthen X \xelse Y) = ?Z$ which encodes the normalization problem. A proven proposition $\XNIF(c,X,Y,?Z)$ states $?Z$ is an answer of the problem and $?Z$ should be in MTF.
\small\begin{align*}
& \begin{array}{ll}
(\forall v.\; \XNIF(c,X\,v,Y,?Z\,v)) \Longrightarrow \XNIF(c,\; \exists X,\; Y,\; \exists ?Z)\\
(\forall v.\; \XNIF(c,X,Y\,v,?Z\,v)) \Longrightarrow \XNIF(c,\; X,\; \exists Y,\; \exists ?Z)
\end{array}
&\parbox{4cm}{Rules merging existential quantifications\footnotemark{}}\\
& \begin{array}{ll}
\XNIF(c,X,Y,?Z) \Longrightarrow \XNIF(c,\; X \land P,\; Y,\; ?Z \land (c \longrightarrow P))\\
\XNIF(c,X,Y,?Z) \Longrightarrow \XNIF(c,\; X,\; Y \land P,\; ?Z \land (\lnot c \longrightarrow P))
\end{array} &\parbox{4cm}{Rules merging conjunctions in two branches}
\end{align*}\normalsize
\footnotetext{For universal quantifications in the logic programming, we demand a resolution feature named \emph{lifting over parameters} given in \cite{lifting_parameters_1,lifting_parameters_2}}%
Then for φ-types separated by ($\ast$) in two branches, we require the lengths of two branches are identical and
for each φ-type $x \tycolon T$ in one branch, we permute the φ-types in the other branch to find a φ-type $y \tycolon T$
of the identical abstraction relation $T$ with $x \tycolon T$, so we can merge the φ-type by applying the following rule.
\[ \XNIF(c,X,Y,?Z) \Longrightarrow
\XNIF(c,\; X \ast x \tycolon T,\; Y\ast y \tycolon T,\; ?Z \ast (\xif c \xthen x \xelse y)\tycolon T) \]
The process continues until all φ-types are merged, or fails if any φ-type cannot find its counterpart in the other branch.
In the end it rewrites $(\xif c \xthen X \xelse Y)$ into MTF.

The above algorithm is merely a schema, and alternative choices are available for small designs. For example, we may merge two quantified variables $v_1,v_2$ to an identical variable $v$, $(\forall v.\; \XNIF(c,X\,v,Y\,v,?Z\,v)) \Longrightarrow \XNIF(c,\; \exists v_1.\,X\,v_1,\; \exists v_2.\,Y\,v_2,\; \exists v.\,?Z\,v)$, if the programmer regards $v_1$ and $v_2$ referring to an identical object, and we may determine this by checking whether the name of the variables are equal.

Any assertion can be represented in infinite MTFs and a good solution is the one that reflects the abstraction intuitively and tangibly.
Since there is no way to define the optimal solution that is the most intuitive, solver for normalization problems is more a matter of choices and designs.


\subsection{Solvers for VCG-ToA}\label{solve-VCG-ToA}

Solvers in the sub-section are based on a parameterized set of transformation rules, and the solver manages to compose the desired transformation step-wisely using rules in the set.
We do not address the transformation between arbitrary abstraction relations that is not deducible from the pre-proven rules because it is considered as hard as proving an arbitrary implication.

The rules are HHFs generated (cf. \cref{HHF}) from set $\mathcal{R} \triangleq \{!P\;,\; X \longrightarrow Y\}$ and the conclusion of a rule must be in form $X \longrightarrow Y$. $X,Y$ are in MTF.
In antecedents, $!P$ represents a VC generated or claimed by the rule and the $P$ should be abstract w.r.t to the abstraction relation in the rule (cf. \cref{VCG-ToA}); $X' \longrightarrow Y'$ represents a sub-goal.
%A sub-goal can be conditioned recursively as the logic programming over HHFs.
A rule of conclusion $X \longrightarrow Y$ gives an deduction from \emph{domain} $X$ to \emph{codomain} $Y$, conditioned by potential VCs and sub-goals.

%The problem is semi-solvable if in a given set of rules, a path of instantiations of the rules exists to deduce the goal transformation, using only first-order unification.

We first give an algorithm based on breadth-first search of graph, by noticing that, ignoring the antecedents, (instantiations of) the rules constitute a graph where each rule is a directed edge from the domain to the codomain.
Because $(\longrightarrow)$ is transitive, the algorithm to a deduction of $X \longrightarrow Y$ in the problem~\ref{prob1} is then searching a path in the graph from the source $X$ to the destination $Y$.
The search starts from $X \vdash X$ and explores sequents by applying transformation rules in a breadth-first manner until it reaches the destination $\Gamma \vdash Y$ for some $\Gamma$.
The conclusions of the sequents in the search are closed in MTF, and the hypotheses $\Gamma$ consist of the source $X$ and the generated VCs in form $!P$. The final output is $\bigwedge (\Gamma - \{X\})$ because $\Gamma \vdash Y$ implies $\vdash \bigwedge (\Gamma - \{X\}) \Longrightarrow (X \longrightarrow Y)$.

\begin{algorithm}[BFS for VCG-ToA]\label{alg1}
  Given the desired destination $Y$ and a sequent $\Gamma_0 \vdash X$ as the root of the search,
  the algorithm is a breadth-first search where for each iteration on sequent $\Gamma \vdash \{ x \tycolon T \mbar_{\vec a} P\}$ it explores the next branches by means of deducing sequents as the following,

  If the present sequent contains leading existential quantifications, (i.e., $\vec a$ are non-empty), fix them by Hilbert choice ($\xepsilon \phi$), viz., from $\Gamma \vdash \exists \phi$ deduce $\Gamma \vdash \phi (\xepsilon \phi)$.
 
  Then, enumerate all the transformation rules and try to apply them by the following inference rule under a procedural interpretation, % (like logic programming),
\small\begin{multline} 
  (\Gamma \vdash \{x \tycolon T \mbar P\}) \Longrightarrow
  (\vdash A \longrightarrow \{x' \tycolon T' \mbar_{\vec a} P'\} \longrightarrow \{ y \tycolon U \mbar_{\vec b} Q \}) \Longrightarrow
\\
  x \tycolon T \equiv\, ?R \ast (x' \tycolon T')[?\vec a/\vec a] \Longrightarrow
  (\Gamma; !(P \longrightarrow P') \vdash A \longrightarrow \{ ?R \ast y \tycolon U \mbar_{\vec b} P \land Q \})
   \label{STEP_imp}
\end{multline}\normalsize
The first and the second antecedent are the present sequent and the transformation rule to be attempted respectively.
$A$ in aggregated conjunction form (cf. \cref{ACF}) are antecedents of the transformation.

The third antecedent represents a unification. The algorithm considers only first-order unification and also permutations of the items in $x \tycolon T \equiv \Asterisk_i^n x_i \tycolon T_i$ separated by $\ast$, by enumerating all the possible $n^2$ permutations.
$?R$ emphasizes $?R$ is an unfixed free variable able to be instantiated in unification.
$[?\vec a/\vec a]$ substitutes unfixed free variables $?\vec a$ for quantified variables $\vec a$.
If the unification fails, the search branch fails.

%We use a frame variable $?R$ here instead of a wand (like applying $X' \longrightarrow Y'$ from $(X' \wand X) \ast X'$ to $(X' \wand X) \ast Y'$) because wand breaks MTF.

In the concluded sequent, $!(P\longrightarrow P')$ is a generated VC that is pure and abstract.
Antecedents $A$ are addressed successively as the following,
\begin{itemize}
    \item For antecedents which are pure assertions, $\Gamma' \vdash\; !P \Longrightarrow C$, move $!P$ into hypotheses directly as a VC. Deduce $\Gamma'; !P \vdash C$.
    \item For sub-goals, $\Gamma' \vdash \forall\vec v(X' \longrightarrow Y') \Longrightarrow C$, rewrite it to $\Gamma' \vdash \exists\vec v((X' \longrightarrow Y') \Longrightarrow C)$ and instantiate $\vec v$ by Hilbert choice.
    Then consider only sequents without quantifications, $\Gamma' \vdash (X' \longrightarrow Y') \Longrightarrow C$.
    Activate the algorithm~\ref{alg1} recursively with input $Y'$ and $\Gamma'; X' \vdash X'$ with fixed $\vec v$. It returns $\Gamma''; X' \vdash Y'$ for some $\Gamma''$ with $X' \notin \Gamma''$.
      Then we have $\Gamma' \cup \Gamma'' \vdash C$.
\end{itemize}
If any antecedent fails to be solved, the search branch fails.

Summarily, from $\Gamma \vdash \{x \tycolon T \mbar P\}$ via the transformation rule given in the second antecedent of \cref{STEP_imp} the search explores $(\Gamma_3 \vdash \{ ?R \ast y \tycolon U \mbar_{\vec b} P \land Q \})$ for some $\Gamma_3$ and $?R$, if the unification and all the antecedents succeed.

  The breadth-first search continues until it reaches the desired $\Gamma_4 \vdash Y$ for some $\Gamma_4$.
  The algorithm does not always terminate but is terminable once in the given set of rules there is a finite path of instantiations of rules from the source $X$ to the destination $Y$, for the goal $X \longrightarrow Y$, where all the sub-goals in the antecedents of the rules also have a such finite path.
  Because the length of the path is finite and the sub-goals in each rule are also finite, the search is terminable once there is a solution, and can be non-terminable if not.

%The reasoning rule states, starting from $\{\Asterisk_i^n x_i \tycolon T_i \mbar P\}$, via unification and frame rule (of $?R$),
%the transformation of abstraction in the middle line is appliable, and it results in $\{ ?R \ast \Asterisk_j^m y_j \tycolon U_j \mbar_{\vec b} P \land Q \}$ with \emph{pure} and \emph{abstract} verification condition $!(P \longrightarrow P')$.

\end{algorithm}

The above BFS is a bit inefficient because it traverses many paths not used in the final output.
In the actual implementation, we use instead a heuristic depth-first search (DFS) guided by manually configured priority in a logic programming manner with controls of cut and ad-hoc solvers for specific forms of antecedent.
It realizes a generally good performance as demonstrated in the case study \cref{???}.

\subsection{Solvers for CoA}\label{solve-CoA}

In the automation of usual Hoare Logics, the path of applying inference rules is deterministic and unique.
In contrast, due to various choices of abstractions of a single operation, the path in φ-SL is not uniquely determined.
It resembles the situation in programming --- there are many choices of different sub-routines to do the same work.
In view of this, the intuition of CoP is to push choices back to programmers --- by lifting the programming onto the abstractions, programmers choose different abstract sub-routines i.e. use abstract specifications to write the concrete program, which decides the path of applying rules.
Indeed in this abstract programming, programmers can focus on only the abstract specifications, just with little knowledge about the efficiency of the concrete implementation, just like the usual programming behaviors that use library functions according to documents, a kind of informal specification.


